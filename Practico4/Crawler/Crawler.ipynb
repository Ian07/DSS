{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Desarrolle un crawler para el sitio web del Diario Jornada, que almacene la información de las secciones más relevantes de la página en una base de datos. Exponga una API que permita consultar los datos de acuerdo a ciertos parámetros.\n",
    "Además resolver y graficar las siguientes operaciones:\n",
    "1. Mostrar cuales son las 5 noticias más relevantes seg ́un cantidad de visitas a nivel global y por sección.\n",
    "2. Mostrar como están distribuidas las palabras de cierto artículo.\n",
    "3. Mostrar el número promedio, máximo y mínimo de palabras, sentencias, párrafos de un conjunto de noticias de su preferencia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para desarrollar un crawler usaremos la libreria **Scrapy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrapy\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
